Metadata-Version: 2.4
Name: pyAID
Version: 0.1.0
Summary: Implémentation de l’algorithme AID (Automatic Interaction Detection) pour la régression.
Author-email: DJERI-ALASSANI OUBENOUPOU <djeryala@gmail.com>
License: MIT
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.20
Requires-Dist: matplotlib>=3.5

pyAID: Automatic Interaction Detection in Python
===============================================

Ce package propose une implémentation fidèle et optimisée de l’algorithme AID (Morgan & Sonquist, 1963) pour la régression. L’objectif est pédagogique : illustrer l’approche historique de partitionnement binaire basée sur la réduction de variance, avec les paramètres canoniques R, M et Q.

Caractéristiques
----------------
- AIDRegressor conforme à la logique originale (réduction de variance, F-stat informatif).
- Paramètres R (taille minimale des enfants), M (taille minimale pour tenter un split), Q (profondeur maximale).
- Implémentation vectorisée NumPy et calculs agrégés pour limiter les copies.
- Export JSON, visualisations légères (structure d’arbre et splits).
- Tests unitaires avec pytest et exemples reproductibles (iris, données synthétiques).

Installation locale
-------------------
```bash
cd pyAID
pip install -e .
```

Utilisation rapide
------------------
```python
import numpy as np
from pyAID import AIDRegressor

X = np.random.normal(size=(200, 2))
y = (X[:, 0] > 0).astype(float) + 0.2 * X[:, 1]

model = AIDRegressor(R=5, M=12, Q=4, min_gain=1e-3, store_history=True)
model.fit(X, y)
preds = model.predict(X[:3])
print(model.summary())
```

Organisation du code
--------------------
- `pyAID/aid.py` : classe principale `AIDRegressor`.
- `pyAID/utils.py` : conversions, recherche de split vectorisée.
- `pyAID/tree.py` : structure de nœud et export.
- `pyAID/plotting.py` : visualisation minimaliste.
- `tests/` : tests unitaires avec pytest.
- `examples/` : notebooks illustratifs (iris, données numériques synthétiques).

Hypothèses et choix
-------------------
- L’algorithme suit strictement la sélection du meilleur split par réduction de SSE et F-stat calculé à des fins de diagnostic (pas de CART/CHAID).
- Données supposées numériques ; les variables catégorielles peuvent être encodées en amont.
- Arrêts : profondeur maximale (Q), taille minimale parent (M) et enfants (R), gain minimal optionnel.

Ressources
----------
- Morgan, J. N., & Sonquist, J. A. (1963). *Problems in the analysis of survey data, and a proposal*. Journal of the American Statistical Association, 58(302), 415‑434.
